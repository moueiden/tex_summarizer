{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer packages\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from requests import get\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\morcodou.seck\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\morcodou.seck\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Téléchargement des modules depuis nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nettoyage du text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text_to_clean):\n",
    "    # Supprimer [\\w]*\n",
    "    text_to_clean = re.sub(r'[[\\w]*]', ' ', text_to_clean)\n",
    "\n",
    "    # Supprimer les chaines de \\xa0, \\u200c\n",
    "    text_to_clean = re.sub(r'\\xa0|\\u200c', ' ', text_to_clean)\n",
    "\n",
    "    # Remplacer les espaces multiples par l'espace simple\n",
    "    text_to_clean = re.sub(r'/s+', ' ', text_to_clean)\n",
    "\n",
    "    # Remplacer l'espace en debut et fin de corpus\n",
    "    text_to_clean = re.sub(r'^\\s|\\s$', '', text_to_clean)\n",
    "    \n",
    "    return text_to_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_weight(text, language = 'english'):\n",
    "    # Stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words(language)\n",
    "    \n",
    "    # Dictionnaire de fréquences des mots\n",
    "    word_frequencies = {}\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "                \n",
    "    \n",
    "    maximum_frequency = max(word_frequencies.values()) # Fréquence maximale\n",
    "    # Calculer la fréquence pondérée\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = word_frequencies[word] / maximum_frequency\n",
    "\n",
    "    return word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_score(text, language = 'english'):\n",
    "    sentence_list = nltk.sent_tokenize(text)\n",
    "    word_frequencies = calculate_word_weight(text, language = language)\n",
    "    sentence_scores = {} # Liste des scores de chaque phrase\n",
    "    \n",
    "    # Calculer le score de chaque phrase\n",
    "    for sent in sentence_list:\n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "                        \n",
    "    return sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_text(text, resume_size, language = 'english'):\n",
    "    sentence_scores = get_sentences_score(text, language = language)\n",
    "    \n",
    "    # Ordonner les phrases par pondération et recupérer les \"resume_size\" premières phrases\n",
    "    summary_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=False)[:resume_size]\n",
    "    \n",
    "    # regrouper ensemble les phrases qui ont les poids les plus élévés\n",
    "    summary = ' '.join(summary_sentences)\n",
    "\n",
    "    # Afficher le résumé\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Text summarization avec sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les packages\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_textRankSummarizer(text, resume_size, language = 'english'):\n",
    "    # Importer le TextRankSummarizer\n",
    "    from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "    # Initialiser le modèle\n",
    "    summarizer_textrank = TextRankSummarizer()\n",
    "    \n",
    "    # Créer un text parser utilisant de tokenisation\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "\n",
    "    # Summariser en 5 phrases\n",
    "    summary = summarizer_textrank(parser.document, resume_size)\n",
    "\n",
    "    # Regrouper les phrases\n",
    "    text_summary = \"\"\n",
    "    for sentence in summary:\n",
    "        text_summary += str(sentence)\n",
    "\n",
    "    # Retourner le summary\n",
    "    return text_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_lexRankSummarizer(text, resume_size, language = 'english'):\n",
    "    # Importer LexRankSummarizer\n",
    "    from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "    \n",
    "    # Initialiser le modèle\n",
    "    summarizer_lexrank = LexRankSummarizer()\n",
    "    \n",
    "    # Créer un text parser utilisant de tokenisation\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "\n",
    "    # Summariser en 5 phrases\n",
    "    summary = summarizer_lexrank(parser.document, resume_size)\n",
    "\n",
    "    # Regrouper les phrases\n",
    "    text_summary = \"\"\n",
    "    for sentence in summary:\n",
    "        text_summary += str(sentence)\n",
    "        \n",
    "    # Afficher le summary\n",
    "    return text_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_lsaSummarizer(text, resume_size, language = 'english'):\n",
    "    # Importer LsaSummarizer\n",
    "    from sumy.summarizers.lsa import LsaSummarizer\n",
    "    \n",
    "    # Initialiser le modèle\n",
    "    summarizer_lsa = LsaSummarizer()\n",
    "    \n",
    "    # Créer un text parser utilisant de tokenisation\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "\n",
    "    # Summariser en 5 phrases\n",
    "    summary = summarizer_lsa(parser.document, resume_size)\n",
    "\n",
    "    # Regrouper les phrases\n",
    "    text_summary = \"\"\n",
    "    for sentence in summary:\n",
    "        text_summary += str(sentence)\n",
    "\n",
    "    # Afficher le summary\n",
    "    return text_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testons tout ça \n",
    "text = \"\"\"Mark Elliot Zuckerberg naît le 14 mai 1984 à White Plains dans l’État de New York au sein d’une famille juive américaine. Il est le fils de Karen Kempner (née en 1958), psychiatre, et d'Edward Zuckerberg (né en 1954), dentiste.\n",
    "\n",
    "Du côté maternel, Karen Kempner est la fille de Sidney Kempner (1921-2012), fils de Harry Kempner (1892-1936) et Mary Steinberg (vers 1898-1965), et de Gertrude Silver (née en 1924).\n",
    "\n",
    "Du côté paternel, Edward Zuckerberg est le fils de Jacob Zuckerberg (1919-2004), fils de Max Zuckerberg (1899-1948) et de Minnie Wiesenthal ( 1899-1986), et de Miriam Hollander (1920-2004), fille de Max Hollander (1873-1965) et de Rose Schoenfeld (1880-1957), originaires d’Autriche.\n",
    "\n",
    "Avec ses trois sœurs Randi, Donna, et Arielle, Mark Zuckerberg est élevé à Dobbs Ferry, New York.\n",
    "\n",
    "Son père, dentiste, est l'un des premiers à utiliser la radiographie numérique et possède plusieurs ordinateurs. Il lui offre un ordinateur Atari permettant de programmer en Basic. Entre 10 et 12 ans, il crée sa première messagerie, qu'il nomme ZuckNet, et permet à son père de communiquer instantanément avec ses collègues dentistes ou assistants, ainsi qu'avec sa famille. ZuckNet ressemble à une version primitive d'AOL Instant Messenger, sorti un an plus tard, en 1997. Entré au lycée, Mark Zuckerberg programme le logiciel Synapse, qui permet de déterminer les goûts musicaux des utilisateurs et de créer des listes d'écoute. Synapse est cité par des blogs technologiques. AOL et Microsoft veulent l'acquérir et recruter Mark Zuckerberg. Mais il décline leurs offres2,3,4,5. Bill Gates lui aurait offert un million de dollars pour rejoindre Microsoft6. Lorsqu'il entre à l'université Harvard en 2002, il a une réputation de prodige de la programmation. Au début de sa deuxième année, il crée le logiciel CourseMatch, qui permet aux étudiants de déterminer quels cours suivre. Peu après, il crée Facemash, qui permet de noter les étudiants les plus sexys à partir de leurs photos, une application rapidement fermée par l'université2.\n",
    "\n",
    "Au collège, il s'est passionné pour le latin7, et a étudié l'antiquité grecque et romaine8. Il maîtrise l'hébreu, le français, le latin et le grec ancien, et s'est initié au mandarin4,9,5.\"\"\"\n",
    "resume_size = 2\n",
    "language = \"french\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_summury = resume_text(text = text, resume_size = resume_size, language = language)\n",
    "textRank_summury = with_textRankSummarizer(text = text, resume_size = resume_size, language = language)\n",
    "lexRank_summury = with_lexRankSummarizer(text = text, resume_size = resume_size, language = language)\n",
    "lsa_summury = with_lsaSummarizer(text = text, resume_size = resume_size, language = language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mark Elliot Zuckerberg naît le 14 mai 1984 à White Plains dans l’État de New York au sein d’une famille juive américaine.Avec ses trois sœurs Randi, Donna, et Arielle, Mark Zuckerberg est élevé à Dobbs Ferry, New York.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom_summury\n",
    "# textRank_summury\n",
    "# lexRank_summury\n",
    "lsa_summury"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
